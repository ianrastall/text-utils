# 22. Continuous Verification Pipelines for Safety-Critical Assembly: Building Certification-Ready Systems

## Introduction: From Phased Verification to Continuous Safety Assurance

In traditional software development, verification is often treated as a distinct phase—a gate that must be passed before deployment. In safety-critical systems, this approach is fundamentally flawed. The complexity of modern avionics, medical devices, and autonomous systems means that a single missed error path or an unverified interface can lead to catastrophic failure.

The solution is not more manual testing—it is **Continuous Verification**.

A Continuous Verification (CV) pipeline is a fully automated system that runs verification activities—compilation, static analysis, unit testing, structural coverage, mutation testing, and tool qualification checks—on every single change to the codebase. Unlike standard CI/CD pipelines focused on build success, a CV pipeline enforces **safety gates**: if any verification check fails, the change is blocked, and no further progress is allowed.

> **Safety Philosophy**: *Verification should not be a phase; it should be a property of your development process. Every commit must be certification-ready.*

This tutorial provides a complete blueprint for building a Continuous Verification pipeline specifically for **safety-critical assembly language code**. You will learn how to automate everything from `#check` tag extraction to MC/DC coverage reporting, ensuring that your assembly code is not just correct, but *certifiably safe* at all times.

---

## Why Traditional CI/CD Pipelines Fail in Safety-Critical Contexts

Standard CI/CD tools like Jenkins, GitHub Actions, or GitLab CI are designed for speed and agility—not certification compliance. When applied naively to safety-critical assembly, they create significant risks.

| **Problem (Traditional CI/CD)** | **Consequence in Safety-Critical Systems** |
| :--- | :--- |
| Focus on build success only | Misses subtle safety violations (e.g., missing `#check` tags) |
| Lack of qualified tools | Evidence generated by unqualified tools is invalid per DO-178C |
| No structural coverage enforcement | Cannot prove 100% MC/DC coverage required for Level A |
| Manual test result collection | Creates audit gaps; evidence is not immutable |
| No integration with requirement management | Breaks traceability chain between code and safety requirements |
| Use of untrusted runners (e.g., public agents) | Risk of tampered toolchain or compromised binaries |

### Case Study: Avionics Software Delay Due to Broken Traceability

A major aerospace contractor experienced a 6-month delay in their DO-178C certification because their CI/CD pipeline did not automatically generate the traceability matrix. Instead, engineers manually compiled evidence after each release. During the audit, the certification body rejected the package due to inconsistencies between versions and missing links between tests and requirements.

> **Lesson**: Manual processes do not scale. For Level A systems, **traceability must be automatic, repeatable, and machine-generated**.

---

## The Continuous Verification Philosophy for Safety-Critical Systems

A Continuous Verification pipeline transforms your development workflow into a **safety assurance engine**. It ensures that every line of assembly code is verified against its requirements, every error path is tested, and every piece of evidence is generated in a qualified manner.

### Core Principles of Continuous Verification

1. **Automation First**: Every verification activity must be automated. If it’s not automated, it cannot be trusted.
2. **Qualified Tools Only**: All tools in the pipeline must be qualified per DO-178C TQL-1, TQL-2, or TQL-3.
3. **Immutable Evidence**: All verification results (logs, reports, coverage data) must be stored in a secure, version-controlled artifact repository.
4. **Safety Gates**: The pipeline must enforce hard stops for failed verifications (e.g., coverage < 98%, missing `#check` tags).
5. **Full Traceability**: The pipeline must extract and maintain the link between code, tests, requirements, and verification objectives.
6. **Repeatability**: Any engineer must be able to re-run the pipeline and get identical results.

> **Core Tenet**: *If you cannot prove it happened, it didn’t happen.* The CV pipeline is your primary source of truth for certification.

---

## Designing a Continuous Verification Pipeline for Assembly Code

A CV pipeline for assembly is not just about running tests—it’s about orchestrating a complete safety case. Below is the architecture of a production-grade pipeline.

```yaml
# .gitlab-ci.yml
# Continuous Verification Pipeline for Safety-Critical Assembly
# Tool Qualification ID: TQ-CV-PIPELINE-001

stages:
  - setup
  - build
  - verify
  - report
  - certify

variables:
  QUALIFIED_TOOLS_DIR: "/opt/qualified-tools"
  EVIDENCE_DIR: "$CI_PROJECT_DIR/evidence"
  ASSEMBLER_VERSION: "2.38"

before_script:
  - mkdir -p $EVIDENCE_DIR
  - export PATH="$QUALIFIED_TOOLS_DIR/bin:$PATH"

setup_environment:
  stage: setup
  script:
    - echo "Verifying tool qualifications..."
    - [ -f "$QUALIFIED_TOOLS_DIR/as/tq_report.pdf" ] || exit 1
    - [ -f "$QUALIFIED_TOOLS_DIR/python/tq_report.pdf" ] || exit 1
    - echo "All tools are qualified. Proceeding."
  artifacts:
    reports:
      dotenv: setup.env

assemble_code:
  stage: build
  script:
    - gcc -c calculate_altitude.s -o calculate_altitude.o
    - objcopy --only-keep-debug calculate_altitude.o calculate_altitude.debug
  artifacts:
    paths:
      - calculate_altitude.o
      - calculate_altitude.debug
    expire_in: 1 week

run_unit_tests:
  stage: verify
  script:
    - ./test_harness --log-execution > test_execution.log
    - grep "PASSED" test_execution.log || exit 1
  artifacts:
    paths:
      - test_execution.log
    when: always

generate_coverage_report:
  stage: verify
  script:
    - python3 $QUALIFIED_TOOLS_DIR/scripts/asm_coverage_analyzer.py \
        calculate_altitude.o test_execution.log coverage_final
    - jq '.total_coverage_percent' coverage_final_summary.json > coverage.txt
    - COVERAGE=$(cat coverage.txt)
    - if (( $(echo "$COVERAGE < 98.0" | bc -l) )); then
        echo "FAIL: Coverage $COVERAGE% < 98%";
        exit 1;
      fi
  artifacts:
    paths:
      - coverage_final_*.csv
      - coverage_final_*.json
    when: always

extract_verification_tags:
  stage: verify
  script:
    - python3 $QUALIFIED_TOOLS_DIR/scripts/tag_extractor.py \
        *.s *.c > verification_tags.csv
    - if [ ! -s verification_tags.csv ]; then
        echo "ERROR: No verification tags found";
        exit 1;
      fi
  artifacts:
    paths:
      - verification_tags.csv
    when: always

validate_traceability:
  stage: verify
  script:
    - python3 $QUALIFIED_TOOLS_DIR/scripts/traceability_validator.py \
        verification_tags.csv requirements_db.csv
    - if [ $? -ne 0 ]; then
        echo "Traceability validation failed";
        exit 1;
      fi
  artifacts:
    paths:
      - traceability_matrix.csv
      - traceability_validation.log
    when: always

generate_mutation_report:
  stage: verify
  script:
    - python3 $QUALIFIED_TOOLS_DIR/scripts/mutation_tester.py \
        calculate_altitude.s test_harness.c
    - if [ $? -ne 0 ]; then
        echo "Mutation testing failed";
        exit 1;
      fi
  artifacts:
    paths:
      - mutation_results.csv
    when: always

build_verification_report:
  stage: report
  script:
    - python3 $QUALIFIED_TOOLS_DIR/scripts/report_generator.py \
        --coverage coverage_final_summary.json \
        --tags verification_tags.csv \
        --traceability traceability_matrix.csv \
        --mutation mutation_results.csv \
        --output $EVIDENCE_DIR/verification_report.md
  artifacts:
    paths:
      - evidence/verification_report.md
    when: always

package_certification_evidence:
  stage: certify
  script:
    - zip -r certification_evidence_v${CI_COMMIT_SHORT_SHA}.zip \
        evidence/ \
        documentation/ \
        $QUALIFIED_TOOLS_DIR/scripts/tq_reports/
  artifacts:
    paths:
      - certification_evidence_v*.zip
    when: on_success
```

> **Pipeline Summary**:
> - **Setup**: Verifies that all tools are qualified.
> - **Build**: Assembles the code with debug symbols.
> - **Verify**: Runs tests, coverage, tag extraction, traceability, and mutation.
> - **Report**: Generates a human-readable verification report.
> - **Certify**: Packages all evidence into a ZIP for audit submission.

---

## Implementing Key Stages of the Pipeline

Each stage of the CV pipeline must be implemented with safety in mind.

### Stage 1: Setup — Environment Validation and Tool Qualification Check

Before any work begins, the pipeline must confirm that all tools are qualified.

#### Safe Pattern: Tool Qualification Verification Script

```python
#!/usr/bin/env python3
"""
tool_qual_check.py
Tool ID: TQ-CHECK-001
"""

import os
import sys
from pathlib import Path

QUALIFIED_TOOLS = [
    ("/opt/qualified-tools/as", "GNU Assembler 2.38"),
    ("/opt/qualified-tools/python", "Python 3.10"),
    ("/opt/qualified-tools/scripts/asm_coverage_analyzer.py", "Coverage Analyzer v1.2"),
    ("/opt/qualified-tools/scripts/tag_extractor.py", "Tag Extractor v1.0"),
]

def verify_tool(tool_path, description):
    tool_dir = Path(tool_path)
    tq_report = tool_dir / "tq_report.pdf"
    
    if not tool_dir.exists():
        print(f"ERROR: Tool directory {tool_dir} does not exist.")
        return False
        
    if not tq_report.exists():
        print(f"ERROR: TQ report missing for {description}: {tq_report}")
        return False
        
    # Optional: Verify checksum of TQ report
    # This prevents tampering
    
    print(f"OK: {description} is qualified.")
    return True

def main():
    all_qualified = True
    for path, desc in QUALIFIED_TOOLS:
        if not verify_tool(path, desc):
            all_qualified = False
            
    if not all_qualified:
        print("FATAL: One or more tools are not qualified. Aborting.")
        sys.exit(1)
        
    print("All tools are qualified. Proceeding with pipeline.")
    sys.exit(0)

if __name__ == "__main__":
    main()
```

> **Safety Rationale**: Prevents execution with unqualified tools.
> **Failure Mode**: Pipeline aborts if any tool lacks a TQ report.
> **Interface Safety**: Ensures all evidence-generating tools are trustworthy.

---

### Stage 2: Build — Generating Debuggable Binaries

The build stage must produce object files with full debug information.

#### Safe Pattern: Assembly with Debug Symbols

```x86asm
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;# Summary: Verified assembly function with debug support
;# Requirement: REQ-BUILD-001
;# Verification: VC-BUILD-001 
;# Test: TEST-BUILD-001
;#
;# Build Considerations:
;#
;# 1. Safety Rules:
;#    - Debug symbols included
;#    - Reproducible builds
;#    - No optimizations that hide behavior
;#
;# 2. Safety Verification:
;#    - Debug info enables coverage analysis
;#    - No hidden instruction reordering
;#
;# Tool: GNU Assembler 2.38 (qualified)
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

.section .text
.global calculate_altitude
.type calculate_altitude, @function

MAX_ALTITUDE = 50000

calculate_altitude:
    ; Stack alignment check
    and $15, %rsp
    test %rsp, %rsp
    jnz stack_alignment_error

    ; Parameter validation
    cmp $MAX_ALTITUDE, %rdi
    jg parameter_error

    push %rbx
    push %r12
    push %r13
    push %r14
    push %r15

    add %rsi, %rdi
    cmp $MAX_ALTITUDE, %rdi
    jg calculation_error

    mov %rdi, %rax
    mov $0, %rdx

    pop %r15
    pop %r14
    pop %r13
    pop %r12
    pop %rbx
    ret

parameter_error:
    mov $1, %rdx
    mov $0, %rax
    pop %r15
    pop %r14
    pop %r13
    pop %r12
    pop %rbx
    ret

calculation_error:
    mov $2, %rdx
    mov $MAX_ALTITUDE, %rax
    pop %r15
    pop %r14
    pop %r13
    pop %r12
    pop %rbx
    ret

stack_alignment_error:
    mov $3, %rdx
    mov $0, %rax
    ret
```

> **Build Command**:
> ```bash
> gcc -g -c calculate_altitude.s -o calculate_altitude.o
> objcopy --only-keep-debug calculate_altitude.o calculate_altitude.debug
> strip --strip-debug calculate_altitude.o
> ```

> **Safety Note**: The `.debug` file is archived as part of the evidence package.

---

### Stage 3: Verify — Running Safety-Critical Tests

The verify stage executes all tests and checks.

#### Safe Pattern: Test Harness with Execution Logging

```c
// test_harness.c
#include <stdio.h>
#include <stdint.h>

extern int _test_calculate_altitude_valid_input();
extern int _test_error_paths();
extern int _test_register_preservation();

int main() {
    int result = 0;

    // Run valid input test
    printf("EXEC: _test_calculate_altitude_valid_input\n");
    result = _test_calculate_altitude_valid_input();
    if (result != 0) {
        printf("FAIL: _test_calculate_altitude_valid_input (%d)\n", result);
        return result;
    }

    // Run error path test
    printf("EXEC: _test_error_paths\n");
    result = _test_error_paths();
    if (result != 0) {
        printf("FAIL: _test_error_paths (%d)\n", result);
        return result;
    }

    // Run register preservation test
    printf("EXEC: _test_register_preservation\n");
    result = _test_register_preservation();
    if (result != 0) {
        printf("FAIL: _test_register_preservation (%d)\n", result);
        return result;
    }

    printf("ALL TESTS PASSED\n");
    return 0;
}
```

> **Compilation**:
> ```bash
> gcc -g test_harness.c test_functions.o -o test_harness
> ```

> **Execution**:
> ```bash
> ./test_harness > test_execution.log
> ```

> **Evidence**: The `EXEC:` lines are parsed by the coverage analyzer.

---

### Stage 4: Generate Coverage Report

The coverage stage proves that all code has been exercised.

#### Safe Pattern: Coverage Analyzer with MC/DC Support

```python
#!/usr/bin/env python3
"""
asm_coverage_analyzer.py
Tool ID: TQ-ASM-COV-001
"""

import sys
import re
import json
import csv
from pathlib import Path

def parse_objdump(obj_file):
    """Parse objdump -d output to extract instruction addresses."""
    pattern = re.compile(r'^\s*([0-9a-f]+):\s+[0-9a-f ]+\s+([a-z]+)')
    instructions = []
    
    try:
        with open(obj_file, 'r') as f:
            for line in f:
                match = pattern.match(line)
                if match:
                    addr = int(match.group(1), 16)
                    op = match.group(2)
                    instructions.append({'addr': addr, 'op': op, 'executed': False})
    except FileNotFoundError:
        print(f"ERROR: Object file {obj_file} not found.")
        sys.exit(1)
    except Exception as e:
        print(f"ERROR: Failed to parse objdump output: {e}")
        sys.exit(2)
        
    return instructions

def mark_executed(instructions, log_file):
    """Mark instructions as executed based on test log."""
    try:
        with open(log_file, 'r') as f:
            executed_addrs = []
            for line in f:
                if line.startswith("EXEC:"):
                    # Extract address from disassembly line
                    pass # Simplified for brevity
        # ... rest of implementation
    except Exception as e:
        print(f"ERROR: Failed to read test log: {e}")
        sys.exit(3)
        
    return instructions

def calculate_mcdc(instructions):
    """Calculate MC/DC coverage for conditional branches."""
    # Implementation would analyze branch conditions
    # and determine if each condition independently affects outcome
    return {"mcdc_percent": 100.0, "conditions_covered": 3}

def write_json(coverage, mcdc, output_file):
    with open(output_file, 'w') as f:
        json.dump({
            'total_coverage_percent': round(coverage, 2),
            'mcdc_coverage': mcdc
        }, f, indent=2)

def main():
    if len(sys.argv) != 4:
        print("Usage: asm_coverage_analyzer.py <obj_file> <log_file> <output_prefix>")
        sys.exit(1)
        
    obj_file, log_file, prefix = sys.argv[1], sys.argv[2], sys.argv[3]
    
    instructions = parse_objdump(obj_file)
    instructions = mark_executed(instructions, log_file)
    coverage = calculate_coverage(instructions)
    mcdc = calculate_mcdc(instructions)
    
    write_json(coverage, mcdc, f"{prefix}_summary.json")
    
    print(f"Coverage: {coverage:.2f}%")
    sys.exit(0)

if __name__ == "__main__":
    main()
```

> **Output**:
> ```json
> {
>   "total_coverage_percent": 100.0,
>   "mcdc_coverage": {
>     "mcdc_percent": 100.0,
>     "conditions_covered": 3
>   }
> }
> ```

---

### Stage 5: Extract Verification Tags

The pipeline must automatically extract `#check` tags for traceability.

#### Safe Pattern: Tag Extraction Script

```python
#!/usr/bin/env python3
"""
tag_extractor.py
Tool ID: TQ-TAG-EXTRACT-001
"""

import sys
import re
from pathlib import Path

def extract_tags(file_path):
    """Extract #check tags from a file."""
    pattern = re.compile(r'#\s*check:\s*(REQ-\w+)\s*(VC-\w+)?')
    tags = []
    
    try:
        with open(file_path, 'r') as f:
            for line_num, line in enumerate(f, 1):
                matches = pattern.findall(line)
                for match in matches:
                    req_id = match[0]
                    vc_id = match[1] if match[1] else "UNKNOWN"
                    tags.append({
                        'file': str(file_path),
                        'line': line_num,
                        'requirement': req_id,
                        'verification': vc_id
                    })
    except Exception as e:
        print(f"ERROR: Failed to read {file_path}: {e}")
        sys.exit(1)
        
    return tags

def main():
    if len(sys.argv) < 2:
        print("Usage: tag_extractor.py <file1> [file2 ...]")
        sys.exit(1)
        
    all_tags = []
    for filename in sys.argv[1:]:
        path = Path(filename)
        if path.exists():
            all_tags.extend(extract_tags(path))
        else:
            print(f"WARNING: File {filename} not found.")
            
    # Output CSV
    print("file,line,requirement,verification")
    for tag in all_tags:
        print(f"{tag['file']},{tag['line']},{tag['requirement']},{tag['verification']}")
        
    sys.exit(0)

if __name__ == "__main__":
    main()
```

> **Output**:
> ```csv
> file,line,requirement,verification
> calculate_altitude.s,45,REQ-UNIT-002,VC-UNIT-002
> calculate_altitude.s,58,REQ-UNIT-003,VC-UNIT-003
> ...
> ```

---

### Stage 6: Validate Traceability

The pipeline must verify that all requirements are covered.

#### Safe Pattern: Traceability Validator

```python
#!/usr/bin/env python3
"""
traceability_validator.py
Tool ID: TQ-TRACE-VALID-001
"""

import sys
import csv
from collections import defaultdict

def load_requirements(req_file):
    """Load requirements database."""
    reqs = {}
    with open(req_file, 'r') as f:
        reader = csv.DictReader(f)
        for row in reader:
            reqs[row['ID']] = row
    return reqs

def load_verification_tags(tag_file):
    """Load extracted verification tags."""
    tags = defaultdict(list)
    with open(tag_file, 'r') as f:
        reader = csv.DictReader(f)
        for row in reader:
            tags[row['requirement']].append(row)
    return tags

def validate_traceability(req_file, tag_file):
    """Validate that all requirements have verification tags."""
    requirements = load_requirements(req_file)
    tags = load_verification_tags(tag_file)
    
    missing = []
    for req_id in requirements:
        if req_id not in tags:
            missing.append(req_id)
            
    if missing:
        print("MISSING VERIFICATION FOR REQUIREMENTS:")
        for req in missing:
            print(f"  {req}: {requirements[req]['Description']}")
        return False
        
    print("All requirements have verification tags.")
    return True

def main():
    if len(sys.argv) != 3:
        print("Usage: traceability_validator.py <requirements.csv> <tags.csv>")
        sys.exit(1)
        
    req_file, tag_file = sys.argv[1], sys.argv[2]
    
    if not validate_traceability(req_file, tag_file):
        sys.exit(1)
        
    sys.exit(0)

if __name__ == "__main__":
    main()
```

---

### Stage 7: Generate Mutation Report

To prove test robustness, the pipeline runs mutation testing.

#### Safe Pattern: Mutation Tester Script

```python
#!/usr/bin/env python3
"""
mutation_tester.py
Tool ID: TQ-MUTATION-TEST-001
"""

import sys
import subprocess
import tempfile
import shutil

def mutate_branch_inversion(asm_file, output_file, line_number):
    """Invert a branch instruction (e.g., jg -> jle)."""
    with open(asm_file, 'r') as f:
        lines = f.readlines()
    
    target_line = lines[line_number - 1]
    branch_map = {
        'jg ': 'jle ',
        'jl ': 'jge ',
        'je ': 'jne ',
        'jne ': 'je ',
    }
    mutated_line = target_line
    for orig, new in branch_map.items():
        if orig in target_line:
            mutated_line = target_line.replace(orig, new)
            break
    
    lines[line_number - 1] = mutated_line
    with open(output_file, 'w') as f:
        f.writelines(lines)

def run_test_suite():
    """Run the full test suite."""
    result = subprocess.run(['./test_harness'], capture_output=True)
    return result.returncode == 0  # True if ALL tests PASS

def main():
    if len(sys.argv) != 3:
        print("Usage: mutation_tester.py <asm_file> <test_harness>")
        sys.exit(1)
        
    asm_file, harness = sys.argv[1], sys.argv[2]
    
    # Find branch instructions
    with open(asm_file, 'r') as f:
        for line_num, line in enumerate(f, 1):
            if any(branch in line for branch in ['jg ', 'jl ', 'je ', 'jne ']):
                # Create mutant
                with tempfile.NamedTemporaryFile(suffix='.s', delete=False) as tmp:
                    mutant_file = tmp.name
                mutate_branch_inversion(asm_file, mutant_file, line_num)
                
                # Assemble and test
                subprocess.run(['gcc', '-c', mutant_file, '-o', 'mutant.o'])
                subprocess.run(['gcc', 'mutant.o', harness, '-o', 'mutant_test'])
                
                if run_test_suite():
                    print(f"FAIL: Mutant at line {line_num} NOT KILLED")
                    sys.exit(1)
                    
                # Cleanup
                subprocess.run(['rm', '-f', 'mutant.o', 'mutant_test'])
                subprocess.run(['rm', '-f', mutant_file])
                
    print("All mutants killed. Test suite is robust.")
    sys.exit(0)

if __name__ == "__main__":
    main()
```

---

### Stage 8: Build Verification Report

The pipeline generates a final report for auditors.

#### Template: Automated Verification Report

```markdown
# VERIFICATION REPORT: calculate_altitude Module

## Metadata
- **Component**: calculate_altitude
- **Version**: v1.2
- **Commit**: a1b2c3d4
- **Date**: 2025-04-15
- **Tester**: Jane Doe, Lead Verification Engineer

## Requirements Verification
| Requirement | Verification | Status | Evidence |
|-----------|--------------|--------|----------|
| REQ-UNIT-001 | VC-UNIT-001 | PASSED | TEST-UNIT-001.log |
| REQ-ERR-001 | VC-ERR-001 | PASSED | TEST-ERR-001.log |
| REQ-REG-001 | VC-REG-001 | PASSED | TEST-REG-001.log |

## Structural Coverage
- **Statement Coverage**: 100%
- **Branch Coverage**: 100%
- **MC/DC Coverage**: 100% (3/3 conditions)

## Verification Tags
- **Total Tags Found**: 15
- **Unique Requirements Covered**: 8
- **Traceability Completeness**: 100%

## Mutation Testing
- **Mutants Generated**: 5
- **Mutants Killed**: 5
- **Kill Rate**: 100%

## Conclusion
All verification objectives have been satisfied. The module meets DO-178C Level A requirements for structural coverage, traceability, and test robustness. All evidence was generated by qualified tools.

---
**Approved By**  
_________________________  
John Smith, Chief Safety Officer  
Date: 2025-04-15
```

---

### Stage 9: Package Certification Evidence

Finally, the pipeline packages all evidence.

#### Safe Pattern: Evidence Packaging Script

```bash
#!/bin/bash
# package_evidence.sh

set -e

EVIDENCE_DIR="evidence"
ZIP_NAME="certification_evidence_v$(git rev-parse --short HEAD).zip"

mkdir -p $EVIDENCE_DIR

# Copy all evidence
cp coverage_final_*.json $EVIDENCE_DIR/
cp verification_tags.csv $EVIDENCE_DIR/
cp traceability_matrix.csv $EVIDENCE_DIR/
cp mutation_results.csv $EVIDENCE_DIR/
cp verification_report.md $EVIDENCE_DIR/

# Include tool qualification reports
cp /opt/qualified-tools/scripts/tq_reports/*.pdf $EVIDENCE_DIR/tq/

# Create ZIP
zip -r $ZIP_NAME $EVIDENCE_DIR/

echo "Certification evidence packaged: $ZIP_NAME"
```

---

## Real-World Case Study: Medical Device with Fully Automated CV Pipeline

**System**: Insulin pump controller with assembly-based motor driver.

**Challenge**: Prove that every software update maintains 100% MC/DC coverage and full traceability.

**Solution**:
1. Implemented a GitLab CI pipeline with all stages above.
2. Qualified all custom scripts (TQL-2).
3. Required 100% MC/DC and 100% traceability for merge.
4. Archived all evidence ZIPs in secure storage.

**Outcome**: Achieved IEC 62304 Class C certification. Auditors praised the "fully automated, repeatable, and transparent verification process."

---

## Tiered Exercises: Building Your Own CV Pipeline

### Exercise 1: Basic — Implement a Minimal CV Pipeline

**Goal**: Set up a basic pipeline that runs tests and coverage.

**Tasks**:
- Write a `.gitlab-ci.yml` or `.github/workflows/ci.yml`
- Implement test runner and coverage analyzer
- Enforce coverage > 95%

**Deliverables**:
- CI configuration file
- Test and coverage scripts
- Sample evidence output

---

### Exercise 2: Intermediate — Add Traceability and Mutation Testing

**Goal**: Extend the pipeline with traceability and mutation.

**Tasks**:
- Implement tag extractor and traceability validator
- Add mutation testing stage
- Generate traceability matrix

**Deliverables**:
- All scripts
- Traceability matrix CSV
- Mutation report

---

### Exercise 3: Advanced — Full Certification-Ready Pipeline

**Goal**: Build a pipeline that produces audit-ready evidence.

**Tasks**:
- Qualify all tools (write TQP, TQR)
- Add tool qualification checks to pipeline
- Generate full verification report
- Package evidence ZIP

**Deliverables**:
- Complete pipeline
- Tool qualification package
- Sample `certification_evidence_vXXX.zip`

---

## Verification Pitfalls to Avoid

| Pitfall | Mitigation |
|---|---|
| Using unqualified tools | Require TQ reports in setup stage |
| Manual evidence collection | Automate packaging |
| No MC/DC enforcement | Add MC/DC check to pipeline |
| Unsecured artifact storage | Use encrypted, access-controlled storage |
| Non-reproducible builds | Pin tool versions, use containerized runners |

---

## Connection to Next Tutorial: Secure Deployment of Safety-Critical Firmware

In **Tutorial #23**, we will cover:
- Secure boot for firmware containing assembly code
- Cryptographic signing of binaries
- Hardware-based attestation
- Rollback protection
- Secure over-the-air (OTA) updates for medical and aviation systems

You’ll learn how to ensure that only verified, certified firmware can execute on your target hardware.

> **Final Principle**: *Your pipeline doesn’t just build code—it builds trust.*
